{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc1a8a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve the webpage. Status code: 403\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# URL of the endpoint\n",
    "url = \"https://www.sec.gov/Archives/edgar/vprr/index.html\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all folders with class \"grid_10 push_2\"\n",
    "    folders = soup.find_all(\"div\", class_=\"grid_10 push_2\")\n",
    "\n",
    "    # Create a directory to save the downloaded PDFs\n",
    "    os.makedirs(\"downloaded_pdfs\", exist_ok=True)\n",
    "\n",
    "    # Loop through each folder\n",
    "    for folder in folders:\n",
    "        # Find all links (PDFs) in the folder\n",
    "        pdf_links = folder.find_all(\"a\", href=True)\n",
    "\n",
    "        # Loop through each PDF link\n",
    "        for pdf_link in pdf_links:\n",
    "            # Get the absolute URL of the PDF\n",
    "            pdf_url = urljoin(url, pdf_link[\"href\"])\n",
    "\n",
    "            # Download the PDF\n",
    "            response_pdf = requests.get(pdf_url)\n",
    "            \n",
    "            # Extract the PDF name from the URL\n",
    "            pdf_name = pdf_url.split(\"/\")[-1]\n",
    "\n",
    "            # Save the PDF to the \"downloaded_pdfs\" directory\n",
    "            with open(os.path.join(\"downloaded_pdfs\", pdf_name), \"wb\") as pdf_file:\n",
    "                pdf_file.write(response_pdf.content)\n",
    "\n",
    "            print(f\"Downloaded: {pdf_name}\")\n",
    "\n",
    "    print(\"Download completed.\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9e90ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html xmlns=\"http://www.w3.org/1999/xhtml\"><head>\n",
      "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "<title>SEC.gov | Request Rate Threshold Exceeded</title>\n",
      "<style>\n",
      "html {height: 100%}\n",
      "body {height: 100%; margin:0; padding:0;}\n",
      "#header {background-color:#003968; color:#fff; padding:15px 20px 10px 20px;font-family:Arial, Helvetica, sans-serif; font-size:20px; border-bottom:solid 5px #000;}\n",
      "#footer {background-color:#003968; color:#fff; padding:15px 20px;font-family:Arial, Helvetica, sans-serif; font-size:20px;}\n",
      "#content {max-width:650px;margin:60px auto; padding:0 20px 100px 20px; background-image:url(seal_bw.png);background-repeat:no-repeat;background-position:50% 100%;}\n",
      "h1 {font-family:Georgia, Times, serif; font-size:20px;}\n",
      "h2 {text-align:center; font-family:Georgia, Times, serif; font-size:20px; width:100%; border-bottom:solid #999 1px;padding-bottom:10px; margin-bottom:20px;}\n",
      "h3 {font-family:Georgia, Times, serif; font-size:16px; margin:25px 0 0 0;}\n",
      "p {font-family:Verdana, Geneva, sans-serif;font-size:14px;line-height:1.3;}\n",
      ".grey_box {background-color:#eee; padding:5px 40px 20px 40px;margin-top:75px;}\n",
      ".grey_box p {font-size:12px;line-height:1.5}\n",
      ".note {padding: 0 40px; font-style: italic;}\n",
      "</style>\n",
      "</head>\n",
      "<body>\n",
      "<div id=\"header\">U.S. Securities and Exchange Commission</div>\n",
      "<div id=\"content\">\n",
      "<h1>Your Request Originates from an Undeclared Automated Tool</h1>\n",
      "<p>To allow for equitable access to all users, SEC reserves the right to limit requests originating from undeclared automated tools. Your request has been identified as part of a network of automated tools outside of the acceptable policy and will be managed until action is taken to declare your traffic.</p>\n",
      "<p>Please declare your traffic by updating your user agent to include company specific information.</p>\n",
      "<p>For best practices on efficiently downloading information from SEC.gov, including the latest EDGAR filings, visit <a href=\"https://www.sec.gov/developer\" target=\"_blank\">sec.gov/developer</a>. You can also <a href=\"https://public.govdelivery.com/accounts/USSEC/subscriber/new?topic_id=USSEC_260\" target=\"_blank\">sign up for email updates</a> on the SEC open data program, including best practices that make it more efficient to download data, and SEC.gov enhancements that may impact scripted downloading processes. For more information, contact <a href=\"mailto:opendata@sec.gov\">opendata@sec.gov</a>.</p>\n",
      "<p>For more information, please see the SEC’s <a href=\"#internet\">Web Site Privacy and Security Policy</a>. Thank you for your interest in the U.S. Securities and Exchange Commission.\n",
      "</p><p>Reference ID: 0.3c6d3f17.1699883109.1c5f62b9</p>\n",
      "<div class=\"grey_box\">\n",
      "<h2>More Information</h2>\n",
      "<h3><a name=\"internet\">Internet Security Policy</a></h3>\n",
      "<p>By using this site, you are agreeing to security monitoring and auditing. For security purposes, and to ensure that the public service remains available to users, this government computer system employs programs to monitor network traffic to identify unauthorized attempts to upload or change information or to otherwise cause damage, including attempts to deny service to users.</p>\n",
      "<p>Unauthorized attempts to upload information and/or change information on any portion of this site are strictly prohibited and are subject to prosecution under the Computer Fraud and Abuse Act of 1986 and the National Information Infrastructure Protection Act of 1996 (see Title 18 U.S.C. §§ 1001 and 1030).</p>\n",
      "<p>To ensure our website performs well for all users, the SEC monitors the frequency of requests for SEC.gov content to ensure automated searches do not impact the ability of others to access SEC.gov content. We reserve the right to block IP addresses that submit excessive requests.  Current guidelines limit users to a total of no more than 10 requests per second, regardless of the number of machines used to submit requests. </p>\n",
      "<p>If a user or application submits more than 10 requests per second, further requests from the IP address(es) may be limited for a brief period. Once the rate of requests has dropped below the threshold for 10 minutes, the user may resume accessing content on SEC.gov. This SEC practice is designed to limit excessive automated searches on SEC.gov and is not intended or expected to impact individuals browsing the SEC.gov website. </p>\n",
      "<p>Note that this policy may change as the SEC manages SEC.gov to ensure that the website performs efficiently and remains available to all users.</p>\n",
      "</div>\n",
      "<br/>\n",
      "<p class=\"note\"><b>Note:</b> We do not offer technical support for developing or debugging scripted downloading processes.</p>\n",
      "</div>\n",
      "</body></html>\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# URL of the endpoint\n",
    "url = \"https://www.sec.gov/Archives/edgar/vprr/index.html\"\n",
    "\n",
    "# Set up Chrome WebDriver\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode (without opening a browser window)\n",
    "chrome_service = ChromeService(\"/Users/zyper26/Downloads/chromedriver-mac-arm64/chromedriver\")  # Replace with the path to your chromedriver executable\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "# Load the webpage\n",
    "driver.get(url)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html,\"html.parser\")\n",
    "    \n",
    "print(soup)\n",
    "# Find all folders with class \"grid_10 push_2\"\n",
    "folders = driver.find_elements(By.CLASS_NAME, \"grid_10 push_2\")\n",
    "\n",
    "print(folders)\n",
    "# Create a directory to save the downloaded PDFs\n",
    "# os.makedirs(\"downloaded_pdfs\", exist_ok=True)\n",
    "\n",
    "# Loop through each folder\n",
    "for folder in folders:\n",
    "    # Find all links (PDFs) in the folder\n",
    "    pdf_links = folder.find_elements(By.TAG_NAME, \"a\")\n",
    "    print(pdf_links)\n",
    "    # Loop through each PDF link\n",
    "#     for pdf_link in pdf_links:\n",
    "#         # Get the absolute URL of the PDF\n",
    "#         pdf_url = urljoin(url, pdf_link.get_attribute(\"href\"))\n",
    "\n",
    "#         # Download the PDF\n",
    "#         driver.get(pdf_url)\n",
    "\n",
    "#         # Extract the PDF name from the URL\n",
    "#         pdf_name = pdf_url.split(\"/\")[-1]\n",
    "\n",
    "#         # Save the PDF to the \"downloaded_pdfs\" directory\n",
    "#         with open(os.path.join(\"downloaded_pdfs\", pdf_name), \"wb\") as pdf_file:\n",
    "#             pdf_file.write(driver.page_source.encode(\"utf-8\"))\n",
    "\n",
    "#         print(f\"Downloaded: {pdf_name}\")\n",
    "\n",
    "# Close the browser window\n",
    "# driver.quit()\n",
    "# print(\"Download completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
